{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b20fa1",
   "metadata": {},
   "source": [
    "## preb Intern Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729828c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df_intern = pd.read_csv('/Users/faissalfarid/Desktop/bachelorarbeit/datasets/mainData/data_0.0_raw.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete not relevant features\n",
    "df_intern = df_intern.drop(['id', 'ocpptransactionid','created','authenticationtype',\n",
    "                           'validationresult','isbillable','rfid','sigbeginmetervalue',\n",
    "                           'sigendmetervalue','emppartner','cpopartner','platformname',\n",
    "                           'clearingpartner','tariffuid','tariffname','chargepointmodel',\n",
    "                           'chargepointvendor','ocppversion','firmwareversion','iccid',\n",
    "                           'sim_iccid','imsi','sim_imsi','evseid','evseid','evseid',\n",
    "                           'evseid','evseid','evseid','evseid','dsozaehlernummer',\n",
    "                           'meterpublickey','chargingprotocol','voltage','current'\n",
    "                           'chargingprotocol','maxamp', 'connectortype','Unnamed: 0',\n",
    "                           'chargingstop','meterstart','meterstop',\n",
    "                           'connectorid','chargingtype','phase','power',\n",
    "                           'longitude','latitude','country',\n",
    "                           'postalcode','city','region','street','housenumber',\n",
    "                           ], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917836bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#safe data\n",
    "df_intern.to_csv('data_0.1_delNotRelevantFeatures.csv')\n",
    "df_intern = pd.read_csv('/Users/faissalfarid/Desktop/bachelorarbeit/datasets/mainData/data_0.1_delNotRelevantFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation \n",
    "#del all None values\n",
    "#df_intern = df_intern.dropna()\n",
    "\n",
    "#create new feature chargingtime\n",
    "## transform to unixtime\n",
    "df_intern['chargingstart'] = pd.to_datetime(df_intern['chargingstart'])\n",
    "df_intern['chargingstop'] = pd.to_datetime(df_intern['chargingstop'])\n",
    "df_intern['chargingtime'] = df_intern['chargingstop'] - df_intern['chargingstart']\n",
    "df_intern['chargingtime'] = pd.to_timedelta(df_intern['chargingtime'])\n",
    "df_intern['chargingtime'] = df_intern['chargingtime'].dt.total_seconds().div(60).astype(int)\n",
    "#filter only german data\n",
    "df_intern = df_intern[(df_intern['country'] == 'DE')]\n",
    "#Rename collum names: \n",
    "df_intern.rename(columns={'chargingstart': 'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datareduction\n",
    "item_counts = df_intern[\"chargingstation\"].value_counts(normalize=True)\n",
    "item_counts\n",
    "df_intern = df_intern[(df_intern['chargingstation'] =='G120')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee3688",
   "metadata": {},
   "source": [
    "## prep extern data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read extern data\n",
    "preception = pd.read_csv('/Users/faissalfarid/Desktop/bachelorarbeit/datasets/wetherdata/fühlsbüttel/percipition/filteredpreception.csv')\n",
    "wether = pd.read_csv('/Users/faissalfarid/Desktop/bachelorarbeit/datasets/wetherdata/fühlsbüttel/wether/filteredWetherData.csv')\n",
    "sunshine = pd.read_csv('/Users/faissalfarid/Desktop/bachelorarbeit/datasets/wetherdata/fühlsbüttel/sunshine/filteredSunshineData.csv')\n",
    "\n",
    "#change MESS_DATUM in date format\n",
    "FORMAT='%Y%m%d%H'\n",
    "#preception['MESS_DATUM'] = pd.to_datetime(preception['MESS_DATUM'], format=FORMAT)\n",
    "#wether['MESS_DATUM'] = pd.to_datetime(wether['MESS_DATUM'], format=FORMAT)\n",
    "sunshine['MESS_DATUM'] = pd.to_datetime(sunshine['MESS_DATUM'], format=FORMAT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge preception, wether, sunshine by date \n",
    "wether_preception = pd.merge(wether, preception, on=\"MESS_DATUM\",how=\"left\")\n",
    "wether_preception['MESS_DATUM'] = pd.to_datetime(wether_preception['MESS_DATUM'])\n",
    "df_extern = pd.merge(wether_preception, sunshine, on=\"MESS_DATUM\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dff9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop irrelevant collums\n",
    "df_extern = df_extern.drop(['Unnamed: 0_x', 'STATIONS_ID_x','QN_9','eor_x',\n",
    "                           'Unnamed: 0_y','STATIONS_ID_y','QN_8','eor_y',\n",
    "                           'Unnamed: 0','STATIONS_ID','QN_7','eor',\n",
    "                           ], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae0117",
   "metadata": {},
   "source": [
    "## Find epsilon for DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687518eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rcParams['figure.figsize'] = 20,4\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36086738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfc873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date'] = pd.to_numeric(df['date'])\n",
    "X = df[['chargingtime', 'date']]\n",
    "X = df[['date', 'chargingtime']].to_numpy()\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=4)\n",
    "nbrs = neigh.fit(X)\n",
    "distances,indices = nbrs.kneighbors(X)\n",
    "\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "\n",
    "distances = distances[:,1]\n",
    "plt.plot(distances)\n",
    "\n",
    "plt.show()\n",
    "print(\"The optimal value for epsilon will be found at the point of maximum curvature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca195b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_zeros = np.zeros((len(distances),2))\n",
    "arr_zeros = np.zeros((len(distances),2))\n",
    "\n",
    "for i in range(len(arr_zeros)):\n",
    "    arr_zeros[i][0] = i\n",
    "    arr_zeros[i][1] = distances[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['date', 'chargingtime']].to_numpy()\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(X)\n",
    "distances,indices = nbrs.kneighbors(X)\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9158b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneebow.rotor import Rotor\n",
    "\n",
    "rotor = Rotor()\n",
    "rotor.fit_rotate(arr_zeros)\n",
    "elbow_idx = rotor.get_elbow_index()\n",
    "print(elbow_idx)  # 11\n",
    "rotor.plot_elbow()\n",
    "plt.xlabel(\"index\")\n",
    "plt.ylabel(\"neighbour distance\")\n",
    "#safe plt image\n",
    "plt.savefig('test.pdf', dpi=600,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02f0b8",
   "metadata": {},
   "source": [
    "## DSBCA Filter Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a848fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd \n",
    "df = pd.read_csv('test.csv')\n",
    "df['Anomaly'] = 0\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "data = df\n",
    "data_time = data\n",
    "import numpy as np \n",
    "from numpy import random, where\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "#rcParams['figure.figsize'] = 8,6\n",
    "rcParams['figure.figsize'] = 14,4\n",
    "\n",
    "INIT = 1\n",
    "anom_index = INIT\n",
    "\n",
    "# Do the process so long until no anomaly were detected\n",
    "while(np.count_nonzero(anom_index)>0):\n",
    "    #prepare data for model \n",
    "    dbscan_data = data[['date', 'chargingtime']]\n",
    "    df = dbscan_data\n",
    "\n",
    "    #cause dbscan acept only floats make chargingstart numeric\n",
    "    dbscan_data['date']= pd.to_numeric(dbscan_data['date'])\n",
    "\n",
    "    #dbscan_data = dbscan_data.values.astype('float32', copy=False)\n",
    "    dbscan_data\n",
    "    #normalize Data \n",
    "    dbscan_data_scaler = StandardScaler().fit(dbscan_data)\n",
    "    dbscan_data = dbscan_data_scaler.transform(dbscan_data)\n",
    "    X = dbscan_data\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1])\n",
    "    plt.show()\n",
    "\n",
    "    clustering = DBSCAN(eps=0.4, min_samples=4).fit(X)\n",
    "    print(clustering.labels_)\n",
    "    dbscan = DBSCAN(eps = 0.4, min_samples = 4)\n",
    "    print(dbscan)\n",
    "\n",
    "    pred = dbscan.fit_predict(X)\n",
    "    anom_index = where(pred == -1)\n",
    "    print(\"anomalys = \", np.count_nonzero(anom_index))\n",
    "    values = X[anom_index]\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1])\n",
    "    plt.scatter(values[:,0], values[:,1], color='r')\n",
    "    plt.xlabel(\"normalize date\")\n",
    "    plt.ylabel(\"normalize chargingtime\")\n",
    "    plt.show()\n",
    "\n",
    "#################Mark all Anomalys##################\n",
    "    ANOMALY = 888\n",
    "    lenArr = np.count_nonzero(anom_index)    \n",
    "    for i in range(lenArr):\n",
    "        data.iloc[anom_index[0][i],data.columns.get_loc('Anomaly')] = ANOMALY\n",
    "        data_time.iloc[anom_index[0][i],data_time.columns.get_loc('Anomaly')] = ANOMALY\n",
    "        \n",
    "#################Filter Anomalys##################        \n",
    "    data = data[(data['Anomaly'] !=ANOMALY)]    \n",
    "    data_time = data_time[(data_time['Anomaly'] !=ANOMALY)]  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4964a24",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#frequenz ändern \n",
    "##load Data and set index to chargingstart \n",
    "df_intern = pd.read_csv('afterDbscanTest.csv',parse_dates=[2], index_col=[2])\n",
    "\n",
    "#resample and sum chargingtime\n",
    "df_intern = df_intern.resample('H').agg(dict(chargingtime='sum'))\n",
    "\n",
    "#safe resampled dataset\n",
    "\n",
    "for i in range(len(df_intern)-1):\n",
    "    chargingtime = df_intern.iloc[i,df_intern.columns.get_loc('chargingtime')]\n",
    "    if(chargingtime>120):\n",
    "        df_intern.iloc[i,df_intern.columns.get_loc('chargingtime')] = 120\n",
    "        df_intern.iloc[i+1,df_intern.columns.get_loc('chargingtime')] = chargingtime-120\n",
    "df_intern = df_intern.reset_index(drop=False)        \n",
    "df_intern.to_csv('test_after_freq.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c96589",
   "metadata": {},
   "source": [
    "## create new attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('test_after_freq.csv', parse_dates=[1])\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['weekday'] = df['date'].dt.dayofweek\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "#calc weekend\n",
    "df['weekend'] = 88\n",
    "for i in range(len(df)):\n",
    "    day = df.iloc[i,df.columns.get_loc('weekday')]\n",
    "    \n",
    "    if(day >= 5 ):\n",
    "        df.iloc[i,df.columns.get_loc('weekend')] = 1\n",
    "    else:\n",
    "        df.iloc[i,df.columns.get_loc('weekend')] = 0\n",
    "\n",
    "#create occupation\n",
    "LADEPUNKTE = 2 #EVSES\n",
    "df['occupation'] = (df['chargingtime'] / (LADEPUNKTE*60))\n",
    "\n",
    "#calcutae categorie occupation\n",
    "df['categorieOcc'] = 1\n",
    "\n",
    "for i in range(len(df)):\n",
    "    occ = df.iloc[i,df.columns.get_loc('occupation')]\n",
    "    \n",
    "    if(occ >= 0.75):\n",
    "        df.iloc[i,df.columns.get_loc('categorieOcc')] = 1\n",
    "    elif(occ >= 0.5 and occ < 0.75):\n",
    "        df.iloc[i,df.columns.get_loc('categorieOcc')] = 2 \n",
    "    elif(occ >= 0.25 and occ < 0.5): \n",
    "        df.iloc[i,df.columns.get_loc('categorieOcc')] = 3\n",
    "    else:\n",
    "        df.iloc[i,df.columns.get_loc('categorieOcc')] = 4\n",
    "\n",
    "#calcuate binary occupation\n",
    "#df['binaryOcc'] = df['occupation'] < 0.5\n",
    "\n",
    "\n",
    "#bei corr problemem anwenden\n",
    "df['occupation'] = df['occupation']*100\n",
    "df['occupation'] = df['occupation'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_intern_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cf0d5",
   "metadata": {},
   "source": [
    "## merge intern and extern Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0017cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########HHHHHHHOOOOOOOUUUUURRRRLLLLLLYYYYYYY##########\n",
    "\n",
    "#load extern data\n",
    "extern_data = pd.read_csv('final_extern_data.csv')\n",
    "#load intern Data\n",
    "intern_data = pd.read_csv('final_intern_data.csv')\n",
    "\n",
    "#rename collum for extern_data same like intern_data for merging\n",
    "intern_data['date'] = pd.to_datetime(intern_data['date'])\n",
    "extern_data['date'] = pd.to_datetime(extern_data['date'])\n",
    "\n",
    "intern_data['date'] = pd.to_datetime(intern_data['date'], utc = True)\n",
    "extern_data['date'] = pd.to_datetime(extern_data['date'], utc = True)\n",
    "\n",
    "data = pd.merge(intern_data, extern_data, on=\"date\",how=\"left\")\n",
    "del(data['Unnamed: 0_x'])\n",
    "del(data['Unnamed: 0_y'])\n",
    "data.to_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f70ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wetherData.to_csv('final_extern_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71327060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename collum for extern_data same like intern_data for merging\n",
    "extern_data.rename(columns={'MESS_DATUM': 'date'}, inplace=True)\n",
    "intern_data['date'] = pd.to_datetime(intern_data['date'])\n",
    "extern_data['date'] = pd.to_datetime(extern_data['date'])\n",
    "\n",
    "intern_data['date'] = pd.to_datetime(intern_data['date'], utc = True)\n",
    "extern_data['date'] = pd.to_datetime(extern_data['date'], utc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep extern_data\n",
    "del(extern_data['Unnamed: 0'])\n",
    "del(extern_data['RF_TU'])\n",
    "del(extern_data['WRTR'])\n",
    "\n",
    "extern_data.rename(columns={'TT_TU': 'temperature'}, inplace=True)\n",
    "extern_data.rename(columns={'R1': 'precipitation'}, inplace=True)\n",
    "extern_data.rename(columns={'RS_IND': 'bool_precipitation'}, inplace=True)\n",
    "extern_data.rename(columns={'SD_SO': 'sunshine'}, inplace=True)\n",
    "\n",
    "import numpy as np\n",
    "extern_data['  R1'] = extern_data['  R1'].replace(np.nan, 0.0)\n",
    "extern_data['RS_IND'] = extern_data['RS_IND'].replace(np.nan, 0.0)\n",
    "extern_data['SD_SO'] = extern_data['SD_SO'].replace(np.nan, 0.0)\n",
    "\n",
    "extern_data.to_csv('final_extern_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00de04",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85579c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('final_data.csv')\n",
    "data = data.dropna()\n",
    "data_pca = data.drop(['Unnamed: 0', 'date','occupation','categorieOcc',\n",
    "                           ], axis = 1)\n",
    "\n",
    "\n",
    "#Principle Component Analysis PCA\n",
    "from sklearn.decomposition import PCA \n",
    "X = data_pca\n",
    "\n",
    "pca = PCA(n_components=1) \n",
    "pca.fit(X)\n",
    "#pca.components_\n",
    "compressed_data = pca.transform(X)\n",
    "compressed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50934486",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['compressed_data'] = Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d4a49",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7224664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0042926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autocorrelation\n",
    "#source = https://www.youtube.com/watch?v=y8opUEd05Dg&ab_channel=ritvikmath\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "pacf_plot = plot_pacf(df.occupation, lags = 1000)\n",
    "#pd.plotting.autocorrelation_plot(df['occupation']).set_xlim([0, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1289d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract trend \n",
    "from random import randrange\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "series = df['occupation']\n",
    "result = seasonal_decompose(series.tail(1000), model='additive', period=50)\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9010f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "decomposition = sm.tsa.seasonal_decompose(df['occupation'], model='additive')\n",
    "fig = decomposition.plot()\n",
    "from pylab import rcParams\n",
    "#rcParams['figure.figsize'] = 8,6\n",
    "rcParams['figure.figsize'] = [9.0, 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace6717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
